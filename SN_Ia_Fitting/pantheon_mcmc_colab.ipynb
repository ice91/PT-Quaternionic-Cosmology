{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# install\n",
    "!pip install emcee corner --quiet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 1. Load the Pantheon SN Ia Data\n",
    "# -----------------------------------------------\n",
    "# Data file path (make sure the file is uploaded to Colab or located at the correct path)\n",
    "data_path = \"lcparam_full_long_zhel.txt\"\n",
    "\n",
    "# Read the file using whitespace as the delimiter, ignoring lines starting with '#'\n",
    "sn_data = pd.read_csv(data_path, delim_whitespace=True, comment=\"#\",\n",
    "                      header=None,\n",
    "                      names=[\"name\", \"zcmb\", \"zhel\", \"dz\", \"mb\", \"dmb\", \"x1\", \"dx1\",\n",
    "                             \"color\", \"dcolor\", \"3rdvar\", \"d3rdvar\", \"cov_m_s\",\n",
    "                             \"cov_m_c\", \"cov_s_c\", \"set\", \"ra\", \"dec\", \"biascor\"])\n",
    "print(\"Successfully loaded SN Ia data. Data shape:\", sn_data.shape)\n",
    "print(sn_data.head())\n",
    "\n",
    "# Use 'zhel' as redshift, 'mb' as observed magnitude, and 'dmb' as its error.\n",
    "# Note: Here, we define the observed distance modulus as\n",
    "# μ_obs = mb - M, where M is the unknown absolute magnitude (treated as a nuisance parameter).\n",
    "z_data = sn_data[\"zhel\"].values\n",
    "# For now, we treat mb as the relative value of the distance modulus.\n",
    "mu_obs = sn_data[\"mb\"].values  \n",
    "mu_err = sn_data[\"dmb\"].values\n",
    "\n",
    "# To avoid uncertainties at very low redshift (z approaching 0), filter data for z > 0.01.\n",
    "mask = z_data > 0.01\n",
    "z_data = z_data[mask]\n",
    "mu_obs = mu_obs[mask]\n",
    "mu_err = mu_err[mask]\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2. Define the Cosmological Model: Modified Friedmann Equation and Luminosity Distance Calculation\n",
    "# -----------------------------------------------\n",
    "# Here we assume a flat universe (Omega_k = 0), with the model given by:\n",
    "#   H(z) = H0 * sqrt(Omega_m*(1+z)^3 + Omega_eff)\n",
    "# and the distance modulus is defined as:\n",
    "#   μ = 5*log10(d_L) + 25 + M_offset,\n",
    "# where d_L is in Mpc, and M_offset is an offset for the unknown absolute magnitude.\n",
    "c = 299792.458  # Speed of light in km/s\n",
    "\n",
    "def E_z(z, Omega_m, Omega_eff):\n",
    "    return np.sqrt(Omega_m * (1 + z)**3 + Omega_eff)\n",
    "\n",
    "def luminosity_distance(z, H0, Omega_m, Omega_eff):\n",
    "    integral, _ = quad(lambda zp: 1.0 / E_z(zp, Omega_m, Omega_eff), 0, z)\n",
    "    d_L = (1 + z) * (c / H0) * integral  # in Mpc\n",
    "    return d_L\n",
    "\n",
    "def mu_th(z, H0, Omega_m, Omega_eff, M_offset):\n",
    "    # Distance modulus formula: μ = 5*log10(d_L) + 25 + M_offset\n",
    "    d_L = luminosity_distance(z, H0, Omega_m, Omega_eff)\n",
    "    return 5 * np.log10(d_L) + 25 + M_offset\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3. Define the Log-Prior and Log-Likelihood Functions\n",
    "# -----------------------------------------------\n",
    "def log_prior(theta):\n",
    "    # theta includes [H0, Omega_m, Omega_eff, M_offset]\n",
    "    H0, Omega_m, Omega_eff, M_offset = theta\n",
    "    if 50 < H0 < 90 and 0.1 < Omega_m < 0.5 and 0.5 < Omega_eff < 0.9 and -20 < M_offset < 0:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_likelihood(theta, z, mu_obs, mu_err):\n",
    "    H0, Omega_m, Omega_eff, M_offset = theta\n",
    "    mu_model = np.array([mu_th(zi, H0, Omega_m, Omega_eff, M_offset) for zi in z])\n",
    "    chi2 = np.sum(((mu_obs - mu_model) / mu_err)**2)\n",
    "    return -0.5 * chi2\n",
    "\n",
    "def log_probability(theta, z, mu_obs, mu_err):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, z, mu_obs, mu_err)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4. Perform MCMC Parameter Fitting\n",
    "# -----------------------------------------------\n",
    "# Initial guess: H0 = 70 km/s/Mpc, Omega_m = 0.3, Omega_eff = 0.7, M_offset = -19.3 (typical values)\n",
    "initial = np.array([70, 0.3, 0.7, -19.3])\n",
    "ndim = len(initial)\n",
    "nwalkers = 32\n",
    "pos = initial + 1e-2 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=(z_data, mu_obs, mu_err))\n",
    "\n",
    "print(\"Starting MCMC fitting...\")\n",
    "nsteps = 5000  # Adjust the number of steps as needed\n",
    "sampler.run_mcmc(pos, nsteps, progress=True)\n",
    "print(\"MCMC fitting complete!\")\n",
    "\n",
    "samples = sampler.get_chain(discard=int(nsteps/2), flat=True)\n",
    "print(\"Number of posterior samples:\", samples.shape)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 5. Analyze and Visualize the Results\n",
    "# -----------------------------------------------\n",
    "fig_corner = corner.corner(samples, labels=[\"$H_0$\", \"$\\\\Omega_m$\", \"$\\\\Omega_{eff}$\", \"$M_{offset}$\"])\n",
    "plt.show()\n",
    "\n",
    "H0_mcmc, Omega_m_mcmc, Omega_eff_mcmc, M_offset_mcmc = np.median(samples, axis=0)\n",
    "H0_err = np.percentile(samples[:,0], [16,84])\n",
    "Omega_m_err = np.percentile(samples[:,1], [16,84])\n",
    "Omega_eff_err = np.percentile(samples[:,2], [16,84])\n",
    "M_offset_err = np.percentile(samples[:,3], [16,84])\n",
    "print(f\"H0 = {H0_mcmc:.2f} km/s/Mpc, 16/84% = {H0_err[0]:.2f}/{H0_err[1]:.2f}\")\n",
    "print(f\"Omega_m = {Omega_m_mcmc:.3f}, 16/84% = {Omega_m_err[0]:.3f}/{Omega_m_err[1]:.3f}\")\n",
    "print(f\"Omega_eff = {Omega_eff_mcmc:.3f}, 16/84% = {Omega_eff_err[0]:.3f}/{Omega_eff_err[1]:.3f}\")\n",
    "print(f\"M_offset = {M_offset_mcmc:.2f}, 16/84% = {M_offset_err[0]:.2f}/{M_offset_err[1]:.2f}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 6. Plot the Best-Fit Model vs. SN Ia Data\n",
    "# -----------------------------------------------\n",
    "def model_mu(z_array, H0, Omega_m, Omega_eff, M_offset):\n",
    "    return np.array([mu_th(zi, H0, Omega_m, Omega_eff, M_offset) for zi in z_array])\n",
    "\n",
    "z_plot = np.linspace(0.01, 1.8, 100)\n",
    "mu_plot = model_mu(z_plot, H0_mcmc, Omega_m_mcmc, Omega_eff_mcmc, M_offset_mcmc)\n",
    "\n",
    "plt.errorbar(z_data, mu_obs, yerr=mu_err, fmt='o', markersize=3, label='SN Ia Data', alpha=0.6)\n",
    "plt.plot(z_plot, mu_plot, 'r-', lw=2, label='Best-fit Model')\n",
    "plt.xlabel(\"Redshift $z$\")\n",
    "plt.ylabel(\"Distance Modulus $\\\\mu$\")\n",
    "plt.legend()\n",
    "plt.title(\"SN Ia Distance Modulus vs. Redshift\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBest-fit results:\")\n",
    "print(f\"H0 = {H0_mcmc:.2f} km/s/Mpc\")\n",
    "print(f\"Omega_m = {Omega_m_mcmc:.3f}\")\n",
    "print(f\"Omega_eff = {Omega_eff_mcmc:.3f}\")\n",
    "print(f\"M_offset = {M_offset_mcmc:.2f}\")\n",
    "\n",
    "print(\"\\nIf Omega_eff ≈ 0.7, then the predicted dark energy density is consistent with our model's prediction (~10^-47 GeV^4).\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
